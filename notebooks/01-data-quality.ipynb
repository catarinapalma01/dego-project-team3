{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccd3e306",
   "metadata": {},
   "source": [
    "# 01 — Data Quality & Cleaning Pipeline\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658dfdda",
   "metadata": {},
   "source": [
    "This notebook loads the NovaCred credit application JSON dataset, performs a data quality audit, and applies remediation steps to produce analysis-ready datasets.\n",
    "\n",
    "**Input:** `data/raw/raw_credit_applications.json` \n",
    "\n",
    "**Outputs:**  \n",
    "- `data/processed/applications_clean.csv` (cleaned, may still contain PII)  \n",
    "- `data/processed/applications_analysis_ready.csv` (PII removed for analysis)\n",
    "\n",
    "The notebook covers duplicate records, missing/incomplete values, inconsistent data types, inconsistent categorical coding, inconsistent date formats, invalid/impossible values, and internal consistency checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "id": "9d65d80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import json\n",
    "import warnings\n",
    "import ipaddress\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f887c4f",
   "metadata": {},
   "source": [
    "---\n",
    "## 0. Load & schema sanity check\n",
    "---\n",
    "Before running any quality checks, we first confirm the data loaded correctly, checking the dataset shape, previewing a few rows, and verifying that the key fields we expect from the schema are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "id": "71558222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows, cols: (502, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>spending_behavior</th>\n",
       "      <th>processing_timestamp</th>\n",
       "      <th>applicant_info.full_name</th>\n",
       "      <th>applicant_info.email</th>\n",
       "      <th>applicant_info.ssn</th>\n",
       "      <th>applicant_info.ip_address</th>\n",
       "      <th>applicant_info.gender</th>\n",
       "      <th>applicant_info.date_of_birth</th>\n",
       "      <th>applicant_info.zip_code</th>\n",
       "      <th>...</th>\n",
       "      <th>financials.credit_history_months</th>\n",
       "      <th>financials.debt_to_income</th>\n",
       "      <th>financials.savings_balance</th>\n",
       "      <th>decision.loan_approved</th>\n",
       "      <th>decision.rejection_reason</th>\n",
       "      <th>loan_purpose</th>\n",
       "      <th>decision.interest_rate</th>\n",
       "      <th>decision.approved_amount</th>\n",
       "      <th>financials.annual_salary</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>app_200</td>\n",
       "      <td>[{'category': 'Shopping', 'amount': 480}, {'ca...</td>\n",
       "      <td>2024-01-15T00:00:00Z</td>\n",
       "      <td>Jerry Smith</td>\n",
       "      <td>jerry.smith17@hotmail.com</td>\n",
       "      <td>596-64-4340</td>\n",
       "      <td>192.168.48.155</td>\n",
       "      <td>Male</td>\n",
       "      <td>2001-03-09</td>\n",
       "      <td>10036</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>0.20</td>\n",
       "      <td>31212</td>\n",
       "      <td>False</td>\n",
       "      <td>algorithm_risk_score</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>app_037</td>\n",
       "      <td>[{'category': 'Rent', 'amount': 608}, {'catego...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brandon Walker</td>\n",
       "      <td>brandon.walker2@yahoo.com</td>\n",
       "      <td>425-69-4784</td>\n",
       "      <td>10.1.102.112</td>\n",
       "      <td>M</td>\n",
       "      <td>1992-03-31</td>\n",
       "      <td>10032</td>\n",
       "      <td>...</td>\n",
       "      <td>51</td>\n",
       "      <td>0.18</td>\n",
       "      <td>17915</td>\n",
       "      <td>False</td>\n",
       "      <td>algorithm_risk_score</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>app_215</td>\n",
       "      <td>[{'category': 'Rent', 'amount': 109}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scott Moore</td>\n",
       "      <td>scott.moore94@mail.com</td>\n",
       "      <td>370-78-5178</td>\n",
       "      <td>10.240.193.250</td>\n",
       "      <td>Male</td>\n",
       "      <td>1989-10-24</td>\n",
       "      <td>10075</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>0.21</td>\n",
       "      <td>37909</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vacation</td>\n",
       "      <td>3.7</td>\n",
       "      <td>59000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       _id                                  spending_behavior  \\\n",
       "0  app_200  [{'category': 'Shopping', 'amount': 480}, {'ca...   \n",
       "1  app_037  [{'category': 'Rent', 'amount': 608}, {'catego...   \n",
       "2  app_215              [{'category': 'Rent', 'amount': 109}]   \n",
       "\n",
       "   processing_timestamp applicant_info.full_name       applicant_info.email  \\\n",
       "0  2024-01-15T00:00:00Z              Jerry Smith  jerry.smith17@hotmail.com   \n",
       "1                   NaN           Brandon Walker  brandon.walker2@yahoo.com   \n",
       "2                   NaN              Scott Moore     scott.moore94@mail.com   \n",
       "\n",
       "  applicant_info.ssn applicant_info.ip_address applicant_info.gender  \\\n",
       "0        596-64-4340            192.168.48.155                  Male   \n",
       "1        425-69-4784              10.1.102.112                     M   \n",
       "2        370-78-5178            10.240.193.250                  Male   \n",
       "\n",
       "  applicant_info.date_of_birth applicant_info.zip_code  ...  \\\n",
       "0                   2001-03-09                   10036  ...   \n",
       "1                   1992-03-31                   10032  ...   \n",
       "2                   1989-10-24                   10075  ...   \n",
       "\n",
       "  financials.credit_history_months  financials.debt_to_income  \\\n",
       "0                               23                       0.20   \n",
       "1                               51                       0.18   \n",
       "2                               41                       0.21   \n",
       "\n",
       "   financials.savings_balance  decision.loan_approved  \\\n",
       "0                       31212                   False   \n",
       "1                       17915                   False   \n",
       "2                       37909                    True   \n",
       "\n",
       "   decision.rejection_reason loan_purpose decision.interest_rate  \\\n",
       "0       algorithm_risk_score          NaN                    NaN   \n",
       "1       algorithm_risk_score          NaN                    NaN   \n",
       "2                        NaN     vacation                    3.7   \n",
       "\n",
       "   decision.approved_amount  financials.annual_salary  notes  \n",
       "0                       NaN                       NaN    NaN  \n",
       "1                       NaN                       NaN    NaN  \n",
       "2                   59000.0                       NaN    NaN  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing expected columns: set()\n"
     ]
    }
   ],
   "source": [
    "# Raw file path\n",
    "data_path = Path(\"../data/raw/raw_credit_applications.json\")\n",
    "\n",
    "# Read JSON\n",
    "with data_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    apps = json.load(f)\n",
    "\n",
    "# Flatten nested JSON into a tabular DataFrame\n",
    "df_raw = pd.json_normalize(apps, sep=\".\")\n",
    "\n",
    "# Basic sanity checks\n",
    "print(\"rows, cols:\", df_raw.shape)\n",
    "display(df_raw.head(3))\n",
    "\n",
    "# Check expected columns\n",
    "expected = {\n",
    "    \"_id\",\n",
    "    \"spending_behavior\",\n",
    "    \"processing_timestamp\",\n",
    "    \"applicant_info.full_name\",\n",
    "    \"applicant_info.ssn\",\n",
    "    \"financials.annual_income\",\n",
    "    \"financials.credit_history_months\",\n",
    "    \"financials.debt_to_income\",\n",
    "    \"financials.savings_balance\",\n",
    "    \"decision.loan_approved\",\n",
    "}\n",
    "\n",
    "missing = expected - set(df_raw.columns)\n",
    "print(\"Missing expected columns:\", missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c290efb0",
   "metadata": {},
   "source": [
    "The dataset was loaded successfully (502 rows, 21 columns) and all key expected columns are present."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dde085",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Data quality checks: `spending_behavior`\n",
    "---\n",
    "\n",
    "`spending_behavior` is a nested list of spending entries (each entry has a category and an amount). Since it’s an “array of objects”, we can’t treat it like a normal column, meaning we need to unpack it first so we can run data quality checks. After that, we check missing/incomplete entries, consistent data types, valid values, and consistent category formatting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63548002",
   "metadata": {},
   "source": [
    "### 1A. Create an analysis table\n",
    "\n",
    "To check quality at the entry level, we explode the list so each spending entry becomes its own row. This gives us a clean table (`spend`) where each row is one item (`category`, `amount`)  linked to the original application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "id": "e9e079ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total spending entries: 827\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>category</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>app_200</td>\n",
       "      <td>Shopping</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>app_200</td>\n",
       "      <td>Rent</td>\n",
       "      <td>790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>app_200</td>\n",
       "      <td>Alcohol</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>app_037</td>\n",
       "      <td>Rent</td>\n",
       "      <td>608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>app_037</td>\n",
       "      <td>Dining</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>app_037</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>app_215</td>\n",
       "      <td>Rent</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>app_024</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>app_184</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>app_275</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       _id       category  amount\n",
       "0  app_200       Shopping     480\n",
       "1  app_200           Rent     790\n",
       "2  app_200        Alcohol     247\n",
       "3  app_037           Rent     608\n",
       "4  app_037         Dining      96\n",
       "5  app_037     Healthcare     243\n",
       "6  app_215           Rent     109\n",
       "7  app_024        Fitness     575\n",
       "8  app_184  Entertainment     463\n",
       "9  app_275  Entertainment     571"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build an exploded table: one row per spending entry\n",
    "spend = (\n",
    "    df_raw[[\"_id\", \"spending_behavior\"]]\n",
    "    .dropna(subset=[\"spending_behavior\"])\n",
    "    .explode(\"spending_behavior\", ignore_index=True)\n",
    ")\n",
    "\n",
    "# Extract fields safely\n",
    "spend[\"category\"] = spend[\"spending_behavior\"].map(lambda x: x.get(\"category\") if isinstance(x, dict) else None)\n",
    "spend[\"amount\"] = pd.to_numeric(\n",
    "    spend[\"spending_behavior\"].map(lambda x: x.get(\"amount\") if isinstance(x, dict) else None),\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "\n",
    "print(\"Total spending entries:\", len(spend))\n",
    "display(spend[[\"_id\", \"category\", \"amount\"]].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af41db72",
   "metadata": {},
   "source": [
    "### 1B. Missing/incomplete entries\n",
    "\n",
    "**Dimension:** Completeness\n",
    "\n",
    "Here we’re just checking if anything is missing in spending_behavior. First, we check if any applications have spending_behavior missing entirely. Then, once we explode the list into one row per spending entry, we check at the entry level to make sure every entry actually has both fields filled in (category and amount)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "id": "d017e1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applications missing spending_behavior: 0 (0.00%)\n",
      "Missing category entries: 0 (0.00%)\n",
      "Missing amount entries: 0 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "# Total number of rows in the main table\n",
    "n_apps = len(df_raw)\n",
    "\n",
    "# Count applications where spending_behavior is missing\n",
    "missing_sb_apps = df_raw[\"spending_behavior\"].isna().sum()\n",
    "print(\"Applications missing spending_behavior:\", missing_sb_apps, f\"({missing_sb_apps/n_apps*100:.2f}%)\")\n",
    "\n",
    "# Total number of spending entries (rows) after exploding the array\n",
    "n_entries = len(spend)\n",
    "\n",
    "# Count entries where category is missing\n",
    "missing_cat = spend[\"category\"].isna().sum()\n",
    "\n",
    "# Count entries where amount is missing\n",
    "missing_amt = spend[\"amount\"].isna().sum()\n",
    "\n",
    "print(\"Missing category entries:\", missing_cat, f\"({missing_cat/max(n_entries,1)*100:.2f}%)\")\n",
    "print(\"Missing amount entries:\", missing_amt, f\"({missing_amt/max(n_entries,1)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd128f50",
   "metadata": {},
   "source": [
    "`spending_behavior` has 0 missing arrays and 0 entries missing `category` or `amount`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3283173",
   "metadata": {},
   "source": [
    "### 1C. Inconsistent data types\n",
    "\n",
    "**Dimension:** Consistency\n",
    "\n",
    "Now we check if every `category` is a string and every `amount` is a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "id": "44e2280c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-string category entries: 0 (0.00%)\n",
      "Non-numeric/missing amount entries: 0 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "# Count values that aren't strings\n",
    "non_string_cat = (~spend[\"category\"].dropna().map(lambda x: isinstance(x, str))).sum()\n",
    "print(\"Non-string category entries:\", non_string_cat,\n",
    "      f\"({non_string_cat/max(n_entries, 1)*100:.2f}%)\")\n",
    "\n",
    "# Count amounts that are missing or not numeric\n",
    "non_numeric_amount = spend[\"amount\"].isna().sum()\n",
    "print(\"Non-numeric/missing amount entries:\", non_numeric_amount,\n",
    "      f\"({non_numeric_amount/max(n_entries, 1)*100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b9691b",
   "metadata": {},
   "source": [
    "All `spending_behavior` entries have consistent types. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6964d22c",
   "metadata": {},
   "source": [
    "### 1D. Invalid values\n",
    "\n",
    "**Dimensions:** Validity\n",
    "\n",
    "Check for impossible values, in this case, negative spending amounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "id": "7d155c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative amount entries: 0 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "# Count negative amounts\n",
    "neg_amount = int((spend[\"amount\"] < 0).sum())\n",
    "\n",
    "print(\"Negative amount entries:\", neg_amount, f\"({neg_amount/max(n_entries,1)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af864f84",
   "metadata": {},
   "source": [
    "There are no invalid spending amounts. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd429be",
   "metadata": {},
   "source": [
    "### 1E. Category formatting consistency\n",
    "\n",
    "**Dimension:** Consistency\n",
    "\n",
    "We check whether category values are consistently written, meaning if they have the same capitalization and spacing. We compare the raw categories to a normalized version (trimmed + lowercase) to see if multiple raw spellings map to the same category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "id": "0e6e1683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct raw categories: 15\n",
      "Distinct normalized categories: 15\n",
      "No case/spacing variants found.\n"
     ]
    }
   ],
   "source": [
    "# Normalize categories: trim + lowercase\n",
    "raw = spend[\"category\"].astype(\"string\")\n",
    "norm = raw.str.strip().str.lower()\n",
    "\n",
    "print(\"Distinct raw categories:\", raw.dropna().nunique())\n",
    "print(\"Distinct normalized categories:\", norm.dropna().nunique())\n",
    "\n",
    "# Show categories that only differ by case/spacing (if any)\n",
    "variants = raw.groupby(norm).unique()\n",
    "variants = variants[variants.map(len) > 1]\n",
    "\n",
    "if variants.empty:\n",
    "    print(\"No case/spacing variants found.\")\n",
    "else:\n",
    "    display(variants)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cc2c53",
   "metadata": {},
   "source": [
    "The categories are already consistently formatted (15 raw = 15 normalized), so we found no case or spacing variants to standardize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d89dc6",
   "metadata": {},
   "source": [
    "### 1F. Key findings\n",
    "After unpacking the list into an entry-level table, we found no missing categories/amounts, no non-numeric or negative amounts, and no category formatting inconsistencies. Overall, spending_behavior looks clean and consistent and doesn't require remediation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ba2d37",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data quality checks: Main table\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0dde2b",
   "metadata": {},
   "source": [
    "The main table has one row per application, so we check data quality at the application level. Here we focus on the core fields (applicant info, financials, decision) and look for the data quality issues mentioned previously. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5684984f",
   "metadata": {},
   "source": [
    "### 2A. Duplicate records \n",
    "\n",
    "**Dimension:** Uniqueness\n",
    "\n",
    "Each application in the dataset should be unique, so we check for duplicates using the two identifiers: duplicate application IDs (`_id`) and duplicate applicant Social Security Numbers (`applicant_info.ssn`, excluding missing values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "id": "dff40635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate _id: 2 (0.40%)\n",
      "Missing SSN: 5 (1.00%)\n",
      "Duplicate SSN (excluding missing): 3 (0.60% of non-missing SSNs)\n"
     ]
    }
   ],
   "source": [
    "# Total number of applications\n",
    "n = len(df_raw)\n",
    "\n",
    "# ID duplicates\n",
    "dup_id = df_raw[\"_id\"].duplicated().sum()\n",
    "\n",
    "# SSN duplicates (excluding missing)\n",
    "ssn = df_raw[\"applicant_info.ssn\"]\n",
    "missing_ssn = ssn.isna().sum()\n",
    "dup_ssn_excl_missing = ssn.dropna().duplicated().sum()\n",
    "n_non_missing_ssn = ssn.notna().sum()\n",
    "\n",
    "print(\"Duplicate _id:\", dup_id, f\"({dup_id/n*100:.2f}%)\")\n",
    "print(\"Missing SSN:\", missing_ssn, f\"({missing_ssn/n*100:.2f}%)\")\n",
    "print(\"Duplicate SSN (excluding missing):\", dup_ssn_excl_missing,\n",
    "      f\"({dup_ssn_excl_missing/max(n_non_missing_ssn,1)*100:.2f}% of non-missing SSNs)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feec54d",
   "metadata": {},
   "source": [
    "Results show 2 duplicate application IDs (0.40%), and 3 duplicate SSNs among non-missing values (0.60%), indicating uniqueness issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "id": "7b91d295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>applicant_info.full_name</th>\n",
       "      <th>applicant_info.ssn</th>\n",
       "      <th>processing_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>app_001</td>\n",
       "      <td>Stephanie Nguyen</td>\n",
       "      <td>427-90-1892</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>app_001</td>\n",
       "      <td>Stephanie Nguyen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>app_042</td>\n",
       "      <td>Joseph Lopez</td>\n",
       "      <td>652-70-5530</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>app_042</td>\n",
       "      <td>Joseph Lopez</td>\n",
       "      <td>652-70-5530</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         _id applicant_info.full_name applicant_info.ssn processing_timestamp\n",
       "383  app_001         Stephanie Nguyen        427-90-1892                  NaN\n",
       "455  app_001         Stephanie Nguyen                NaN                  NaN\n",
       "8    app_042             Joseph Lopez        652-70-5530                  NaN\n",
       "354  app_042             Joseph Lopez        652-70-5530                  NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>applicant_info.full_name</th>\n",
       "      <th>applicant_info.ssn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>app_042</td>\n",
       "      <td>Joseph Lopez</td>\n",
       "      <td>652-70-5530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>app_042</td>\n",
       "      <td>Joseph Lopez</td>\n",
       "      <td>652-70-5530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>app_088</td>\n",
       "      <td>Susan Martinez</td>\n",
       "      <td>780-24-9300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>app_016</td>\n",
       "      <td>Gary Wilson</td>\n",
       "      <td>780-24-9300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>app_101</td>\n",
       "      <td>Sandra Smith</td>\n",
       "      <td>937-72-8731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>app_234</td>\n",
       "      <td>Samuel Hill</td>\n",
       "      <td>937-72-8731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         _id applicant_info.full_name applicant_info.ssn\n",
       "8    app_042             Joseph Lopez        652-70-5530\n",
       "354  app_042             Joseph Lopez        652-70-5530\n",
       "92   app_088           Susan Martinez        780-24-9300\n",
       "122  app_016              Gary Wilson        780-24-9300\n",
       "16   app_101             Sandra Smith        937-72-8731\n",
       "499  app_234              Samuel Hill        937-72-8731"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show duplicated _id rows\n",
    "dup_id_rows = df_raw[df_raw[\"_id\"].duplicated(keep=False)].sort_values(\"_id\")\n",
    "display(dup_id_rows[[\"_id\", \"applicant_info.full_name\", \"applicant_info.ssn\", \"processing_timestamp\"]])\n",
    "\n",
    "# Show duplicated SSN rows (excluding missing SSNs)\n",
    "dup_ssn_rows = df_raw[df_raw[\"applicant_info.ssn\"].notna() & df_raw[\"applicant_info.ssn\"].duplicated(keep=False)] \\\n",
    "    .sort_values(\"applicant_info.ssn\")\n",
    "display(dup_ssn_rows[[\"_id\", \"applicant_info.full_name\", \"applicant_info.ssn\"]].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540a44bc",
   "metadata": {},
   "source": [
    "These tables show that the `_id` duplicates appear as repeated application records, and the SSN duplicates appear either within the same `_id` (`app_042`) or across different `_id`s (e.g., the same SSN linked to multiple applications). The latter appear in more than one record with different applicant names, which is an accuracy/cross-field consistency issue. We treat these as SSN collisions.\n",
    "\n",
    "In remediation, we deduplicate `_id` (keeping the most complete record) and flag the remaining SSN duplicates instead of assuming which record is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab6eb04",
   "metadata": {},
   "source": [
    "### 2B. Missing / incomplete records \n",
    "\n",
    "**Dimension:** Completeness\n",
    "\n",
    "#### 2B.1 Missing values\n",
    "\n",
    "We report both missing counts and missing percentages at the application level. Some fields are expected to be conditionally missing, such as rejection reasons, which only exist for denied applications, so we interpret missingness in context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "id": "9580aea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>notes</th>\n",
       "      <td>500</td>\n",
       "      <td>99.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>financials.annual_salary</th>\n",
       "      <td>497</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_purpose</th>\n",
       "      <td>452</td>\n",
       "      <td>90.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>processing_timestamp</th>\n",
       "      <td>440</td>\n",
       "      <td>87.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision.rejection_reason</th>\n",
       "      <td>292</td>\n",
       "      <td>58.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision.approved_amount</th>\n",
       "      <td>210</td>\n",
       "      <td>41.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision.interest_rate</th>\n",
       "      <td>210</td>\n",
       "      <td>41.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>financials.annual_income</th>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>applicant_info.ip_address</th>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>applicant_info.ssn</th>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>applicant_info.date_of_birth</th>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>applicant_info.zip_code</th>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>applicant_info.gender</th>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              missing_count  missing_%\n",
       "notes                                   500      99.60\n",
       "financials.annual_salary                497      99.00\n",
       "loan_purpose                            452      90.04\n",
       "processing_timestamp                    440      87.65\n",
       "decision.rejection_reason               292      58.17\n",
       "decision.approved_amount                210      41.83\n",
       "decision.interest_rate                  210      41.83\n",
       "financials.annual_income                  5       1.00\n",
       "applicant_info.ip_address                 5       1.00\n",
       "applicant_info.ssn                        5       1.00\n",
       "applicant_info.date_of_birth              1       0.20\n",
       "applicant_info.zip_code                   1       0.20\n",
       "applicant_info.gender                     1       0.20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count missing values per column\n",
    "missing_count = df_raw.isna().sum().sort_values(ascending=False)\n",
    "\n",
    "# Percent missing per column\n",
    "missing_pct = (df_raw.isna().mean() * 100).round(2).sort_values(ascending=False)\n",
    "\n",
    "# Combine into one table for reporting\n",
    "missing_table = pd.DataFrame({\n",
    "    \"missing_count\": missing_count,\n",
    "    \"missing_%\": missing_pct\n",
    "})\n",
    "\n",
    "# Only keep columns with at least 1 missing value\n",
    "display(missing_table[missing_table[\"missing_count\"] > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6bdbb5",
   "metadata": {},
   "source": [
    "The most incomplete fields are `notes` (99.6%), `financials.annual_salary` (99.0%), `loan_purpose` (90.0%), and `processing_timestamp` (87.7%).\n",
    "Additionally, several decision-related fields appear conditionally missing, which is expected:\n",
    "  - `decision.approved_amount` and `decision.interest_rate` are missing for 41.83% of records (consistent with applications that were not approved).\n",
    "  - `decision.rejection_reason` is missing for 58.17% of records (consistent with approved applications)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe1354e",
   "metadata": {},
   "source": [
    "The dataset includes both `financials.annual_income` and `financials.annual_salary`, which represent the same underlying concept (yearly income) but are stored as two different variables. Since `annual_salary` is almost always missing, this indicates inconsistent field usage and can confuse downstream analysis.\n",
    "\n",
    "To remediate this situation, we will merge `annual_salary` into `annual_income` whenever `annual_income` is missing but `annual_salary` is available, and then drop `annual_salary` to enforce a single canonical income field.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c78ae9b",
   "metadata": {},
   "source": [
    "#### 2B.2 Blank entries\n",
    "\n",
    "Missingness checks using isna() only capture true NaN values. However, several fields also use blank strings, like \"\" or \" \", to represent “missing”, which would be invisible in the standard missing-value table.\n",
    "\n",
    "Here we quantify blank/empty-string values across all text-like columns to get a more accurate picture of completeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "id": "1b27c822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blank_count</th>\n",
       "      <th>blank_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>applicant_info.email</th>\n",
       "      <td>7</td>\n",
       "      <td>1.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>applicant_info.date_of_birth</th>\n",
       "      <td>4</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>applicant_info.gender</th>\n",
       "      <td>2</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>applicant_info.zip_code</th>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              blank_count  blank_%\n",
       "applicant_info.email                    7     1.39\n",
       "applicant_info.date_of_birth            4     0.80\n",
       "applicant_info.gender                   2     0.40\n",
       "applicant_info.zip_code                 1     0.20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count blank/empty-string values per column\n",
    "s = df_raw.select_dtypes(include=[\"object\", \"string\"]).copy()\n",
    "\n",
    "# Count values that are empty after trimming spaces\n",
    "blank_count = s.apply(lambda col: col.astype(\"string\").str.strip().eq(\"\").sum()).sort_values(ascending=False)\n",
    "\n",
    "# Convert blank counts into percentages of total rows\n",
    "blank_pct   = (blank_count / len(df_raw) * 100).round(2)\n",
    "\n",
    "# Combine into a reporting table\n",
    "blank_table = pd.DataFrame({\n",
    "    \"blank_count\": blank_count,\n",
    "    \"blank_%\": blank_pct\n",
    "})\n",
    "\n",
    "# Show only columns that actually have blanks\n",
    "display(blank_table[blank_table[\"blank_count\"] > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730efc50",
   "metadata": {},
   "source": [
    "The table shows that a small share of records contain blanks entries. \n",
    "\n",
    "In cleaning, we will treat blanks as missing values before any further validation or analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480f1ec4",
   "metadata": {},
   "source": [
    "### 2C. Inconsistent data types \n",
    "\n",
    "**Dimension:** Consistency\n",
    "\n",
    "#### 2C.1 Numeric fields\n",
    "\n",
    "In this step, we verify that fields expected to be numeric are consistently stored as numeric values. Type inconsistencies can break aggregations, distort summary statistics, and cause issues in downstream modelling, so we identify mixed-type columns before remediation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "id": "d61d85dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type counts by column (non-missing values):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>int</th>\n",
       "      <th>str</th>\n",
       "      <th>float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>financials.annual_income</th>\n",
       "      <td>488</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>financials.annual_salary</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>financials.credit_history_months</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>financials.debt_to_income</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>financials.savings_balance</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision.interest_rate</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision.approved_amount</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  int  str  float\n",
       "financials.annual_income          488    8      1\n",
       "financials.annual_salary            0    0      5\n",
       "financials.credit_history_months  502    0      0\n",
       "financials.debt_to_income           0    0    502\n",
       "financials.savings_balance        502    0      0\n",
       "decision.interest_rate              0    0    292\n",
       "decision.approved_amount            0    0    292"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type percentages by column (non-missing values):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>int</th>\n",
       "      <th>str</th>\n",
       "      <th>float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>financials.annual_income</th>\n",
       "      <td>98.19</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>financials.annual_salary</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>financials.credit_history_months</th>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>financials.debt_to_income</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>financials.savings_balance</th>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision.interest_rate</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision.approved_amount</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     int   str  float\n",
       "financials.annual_income           98.19  1.61    0.2\n",
       "financials.annual_salary            0.00  0.00  100.0\n",
       "financials.credit_history_months  100.00  0.00    0.0\n",
       "financials.debt_to_income           0.00  0.00  100.0\n",
       "financials.savings_balance        100.00  0.00    0.0\n",
       "decision.interest_rate              0.00  0.00  100.0\n",
       "decision.approved_amount            0.00  0.00  100.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "numeric_cols = [\n",
    "    \"financials.annual_income\",\n",
    "    \"financials.annual_salary\",\n",
    "    \"financials.credit_history_months\",\n",
    "    \"financials.debt_to_income\",\n",
    "    \"financials.savings_balance\",\n",
    "    \"decision.interest_rate\",\n",
    "    \"decision.approved_amount\",\n",
    "]\n",
    "\n",
    "# For each numeric column, count how many values are int/float/str (excluding NaN)\n",
    "type_counts = {}\n",
    "for col in numeric_cols:\n",
    "    s = df_raw[col]\n",
    "    counts = s.dropna().map(lambda x: type(x).__name__).value_counts()\n",
    "    type_counts[col] = counts.to_dict()\n",
    "\n",
    "# Convert the dictionary into a table\n",
    "type_counts_df = pd.DataFrame(type_counts).fillna(0).astype(int).T\n",
    "\n",
    "print(\"Type counts by column (non-missing values):\")\n",
    "display(type_counts_df)\n",
    "\n",
    "# Percentages (out of non-missing values in each column)\n",
    "non_missing = df_raw[numeric_cols].notna().sum()\n",
    "type_pct_df = (type_counts_df.div(non_missing, axis=0) * 100).round(2)\n",
    "\n",
    "print(\"Type percentages by column (non-missing values):\")\n",
    "display(type_pct_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb9d95c",
   "metadata": {},
   "source": [
    "`financials.annual_income` shows mixed types: most values are numeric, but 8 records store income as strings (and 1 as float), indicating inconsistent typing across records.\n",
    "\n",
    "The other fields are consistently numeric. In remediation, we will convert income fields to numeric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feba34a0",
   "metadata": {},
   "source": [
    "#### 2C.2 String and boolean fields\n",
    "\n",
    "As a quick schema validation step, we verify that fields expected to be strings contain only string values (for non-missing entries), and that `decision.loan_approved` behaves as a boolean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "id": "0bdb8dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id                             0\n",
       "applicant_info.full_name        0\n",
       "applicant_info.email            0\n",
       "applicant_info.ssn              0\n",
       "applicant_info.ip_address       0\n",
       "applicant_info.gender           0\n",
       "applicant_info.date_of_birth    0\n",
       "applicant_info.zip_code         0\n",
       "decision.rejection_reason       0\n",
       "loan_purpose                    0\n",
       "notes                           0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Columns that should be stored as strings \n",
    "expected_str = [\n",
    "    \"_id\",\n",
    "    \"applicant_info.full_name\",\n",
    "    \"applicant_info.email\",\n",
    "    \"applicant_info.ssn\",\n",
    "    \"applicant_info.ip_address\",\n",
    "    \"applicant_info.gender\",\n",
    "    \"applicant_info.date_of_birth\",\n",
    "    \"applicant_info.zip_code\",\n",
    "    \"decision.rejection_reason\",\n",
    "    \"loan_purpose\",\n",
    "    \"notes\",\n",
    "]\n",
    "\n",
    "# Count how many non-missing values aren't strings per column\n",
    "non_string_counts = {}\n",
    "for col in expected_str:\n",
    "    if col in df_raw.columns:\n",
    "        s = df_raw[col]\n",
    "        non_string_counts[col] = int(s.dropna().map(lambda x: not isinstance(x, str)).sum())\n",
    "\n",
    "# Show counts\n",
    "display(pd.Series(non_string_counts).sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "id": "f76a7967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values: [False  True]\n",
      "All boolean? True\n"
     ]
    }
   ],
   "source": [
    "# Boolean check for loan_approved\n",
    "vals = df_raw[\"decision.loan_approved\"].dropna().unique()\n",
    "print(\"Unique values:\", vals)\n",
    "\n",
    "# Confirm all observed values are boolean\n",
    "is_bool = all(isinstance(v, (bool, np.bool_)) for v in vals)\n",
    "print(\"All boolean?\", is_bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b778410b",
   "metadata": {},
   "source": [
    "All fields expected to be strings contain only string values for non-missing entries and `decision.loan_approved` contains only boolean values, so these fields are type-consistent with the schema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2618e33",
   "metadata": {},
   "source": [
    "### 2D. Inconsistent coding/formatting of categorical fields\n",
    "\n",
    "**Dimension:** Consistency  \n",
    "\n",
    "Categorical fields should use consistent representations (e.g., avoid mixing `Male` vs `M`, casing/spacing variants, and blanks). \n",
    "\n",
    "#### 2D.1 `applicant_info.gender`\n",
    "\n",
    "Here we focus on `applicant_info.gender` because it is used downstream for bias/fairness analysis and must be standardized before analysis and reporting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "id": "ab775d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw gender distribution (count and %):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>applicant_info.gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>195</td>\n",
       "      <td>38.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>193</td>\n",
       "      <td>38.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>58</td>\n",
       "      <td>11.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>53</td>\n",
       "      <td>10.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;NA&gt;</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count      %\n",
       "applicant_info.gender              \n",
       "Male                     195  38.84\n",
       "Female                   193  38.45\n",
       "F                         58  11.55\n",
       "M                         53  10.56\n",
       "                           2    0.4\n",
       "<NA>                       1    0.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total shorthand (M+F): 111 (22.11%)\n",
      "Blank + NA: 3 (0.60%)\n"
     ]
    }
   ],
   "source": [
    "# Read gender as a string column so blanks/NA are handled consistently\n",
    "g = df_raw[\"applicant_info.gender\"].astype(\"string\")\n",
    "\n",
    "# Full raw value distribution\n",
    "vc = g.value_counts(dropna=False)\n",
    "vc_pct = (vc / n * 100).round(2)\n",
    "\n",
    "# Combine counts and percentages into one table \n",
    "gender_table = pd.DataFrame({\n",
    "    \"count\": vc,\n",
    "    \"%\": vc_pct\n",
    "})\n",
    "\n",
    "print(\"Raw gender distribution (count and %):\")\n",
    "display(gender_table)\n",
    "\n",
    "# Summary metric for shorthand and blank/missing values\n",
    "n_M = vc.get(\"M\", 0)\n",
    "n_F = vc.get(\"F\", 0)\n",
    "n_blank = vc.get(\"\", 0)\n",
    "n_na = vc.get(pd.NA, 0) \n",
    "\n",
    "print(\"Total shorthand (M+F):\", n_M + n_F, f\"({(n_M+n_F)/n*100:.2f}%)\")\n",
    "print(\"Blank + NA:\", n_blank + n_na, f\"({(n_blank+n_na)/n*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56db08c4",
   "metadata": {},
   "source": [
    "Results show that `applicant_info.gender` is inconsistently coded, mixing full labels (`Male`/`Female`) with shorthand codes (`M`/`F`). The shorthand values represent 22.11% of observations and there's also a small number of balnk/missing entries (0.60%). \n",
    "\n",
    "In the remediation, we will standardize gender coding by mapping `M → Male` and `F → Female`, and convert blank strings to missing to ensure a clean, consistent categorical field."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b2a02b",
   "metadata": {},
   "source": [
    "#### 2D.2 `decision.rejection_reason`\n",
    "\n",
    "We also check `decision.rejection_reason`, which should behave as a categorical field for denied applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "id": "5ceb9503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denied loans: 210\n",
      "Rejection reason non-missing: 210\n",
      "Unique rejection reasons: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>pct_%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision.rejection_reason</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>algorithm_risk_score</th>\n",
       "      <td>170</td>\n",
       "      <td>80.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insufficient_credit_history</th>\n",
       "      <td>23</td>\n",
       "      <td>10.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_dti_ratio</th>\n",
       "      <td>13</td>\n",
       "      <td>6.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low_income</th>\n",
       "      <td>4</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             count  pct_%\n",
       "decision.rejection_reason                \n",
       "algorithm_risk_score           170  80.95\n",
       "insufficient_credit_history     23  10.95\n",
       "high_dti_ratio                  13   6.19\n",
       "low_income                       4    1.9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filter to denied applications and grab rejection_reason\n",
    "rr = df_raw.loc[df_raw[\"decision.loan_approved\"] == False, \"decision.rejection_reason\"].astype(\"string\")\n",
    "\n",
    "# Basic completeness + cardinality\n",
    "print(\"Denied loans:\", (df_raw[\"decision.loan_approved\"] == False).sum())\n",
    "print(\"Rejection reason non-missing:\", rr.notna().sum())\n",
    "print(\"Unique rejection reasons:\", rr.dropna().nunique())\n",
    "\n",
    "# Value distribution (counts + % among non-missing)\n",
    "vc = rr.value_counts(dropna=True)\n",
    "rr_table = pd.DataFrame({\n",
    "    \"count\": vc,\n",
    "    \"pct_%\": (vc / vc.sum() * 100).round(2)\n",
    "})\n",
    "display(rr_table)\n",
    "\n",
    "# (Optional) quick check for messy formatting variants\n",
    "# Shows any labels that differ only by casing/spacing once normalized\n",
    "rr_norm = rr.str.strip().str.lower()\n",
    "variant_check = (\n",
    "    pd.DataFrame({\"raw\": rr.dropna(), \"norm\": rr_norm.dropna()})\n",
    "    .groupby(\"norm\")[\"raw\"].nunique()\n",
    "    .sort_values(ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55493be2",
   "metadata": {},
   "source": [
    "Among denied applications, `decision.rejection_reason` is fully populated (210/210 non-missing) and behaves as a categorical variable with 4 distinct labels. No need for recoding here. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15dd97e",
   "metadata": {},
   "source": [
    "### 2E. Inconsistent date formats\n",
    "\n",
    "**Dimension:** Consistency  \n",
    "\n",
    "In this step, we assess whether the two date fields (`applicant_info.date_of_birth` and `processing_timestamp`) are stored in a consistent way. Specifically, we verify if values in each column can be reliably parsed into datetimes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "id": "9af98493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOB missing: 1 (0.20%)\n",
      "DOB invalid format: 161 (32.07%)\n",
      "processing_timestamp missing: 440 (87.65%)\n",
      "processing_timestamp invalid format: 0 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "dob = df_raw[\"applicant_info.date_of_birth\"]\n",
    "ts  = df_raw[\"processing_timestamp\"]\n",
    "\n",
    "# Try to parse the date fields (invalid formats become NaT)\n",
    "dob_parsed = pd.to_datetime(dob, errors=\"coerce\", utc=False)\n",
    "ts_parsed  = pd.to_datetime(ts, errors=\"coerce\", utc=True)\n",
    "\n",
    "# Identify values that are present but failed to parse\n",
    "invalid_dob = dob.notna() & dob_parsed.isna()\n",
    "invalid_ts  = ts.notna()  & ts_parsed.isna()\n",
    "\n",
    "print(\"DOB missing:\", dob.isna().sum(), f\"({dob.isna().mean()*100:.2f}%)\")\n",
    "print(\"DOB invalid format:\", invalid_dob.sum(), f\"({invalid_dob.mean()*100:.2f}%)\")\n",
    "\n",
    "print(\"processing_timestamp missing:\", ts.isna().sum(), f\"({ts.isna().mean()*100:.2f}%)\")\n",
    "print(\"processing_timestamp invalid format:\", invalid_ts.sum(), f\"({invalid_ts.mean()*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe55609",
   "metadata": {},
   "source": [
    "We can observe that `applicant_info.date_of_birth` has a high rate of unparseable values (161 rows, 32.07%), indicating inconsistent date formats across records. \n",
    "\n",
    "On the other hand, `processing_timestamp` is largely missing (440 rows, 87.65%), but when present it is consistently parseable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "id": "551920c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>applicant_info.date_of_birth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>app_275</td>\n",
       "      <td>14/02/1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>app_099</td>\n",
       "      <td>28/01/1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>app_320</td>\n",
       "      <td>01/12/1978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>app_307</td>\n",
       "      <td>1990/07/26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>app_173</td>\n",
       "      <td>18/07/1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>app_289</td>\n",
       "      <td>20/04/1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>app_075</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>app_274</td>\n",
       "      <td>1986/11/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>app_276</td>\n",
       "      <td>1995/05/07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>app_386</td>\n",
       "      <td>03/20/1968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>app_178</td>\n",
       "      <td>20/07/1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>app_285</td>\n",
       "      <td>1987/06/28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>app_420</td>\n",
       "      <td>1988/04/06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>app_130</td>\n",
       "      <td>03/10/1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>app_108</td>\n",
       "      <td>14/06/1975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        _id applicant_info.date_of_birth\n",
       "5   app_275                   14/02/1982\n",
       "6   app_099                   28/01/1990\n",
       "11  app_320                   01/12/1978\n",
       "14  app_307                   1990/07/26\n",
       "21  app_173                   18/07/1979\n",
       "23  app_289                   20/04/1979\n",
       "26  app_075                             \n",
       "32  app_274                   1986/11/20\n",
       "35  app_276                   1995/05/07\n",
       "36  app_386                   03/20/1968\n",
       "37  app_178                   20/07/1997\n",
       "39  app_285                   1987/06/28\n",
       "41  app_420                   1988/04/06\n",
       "42  app_130                   03/10/1981\n",
       "44  app_108                   14/06/1975"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show a few examples where DOB is present but could not be parsed\n",
    "invalid_dob_rows = df_raw[invalid_dob][[\"_id\", \"applicant_info.date_of_birth\"]].head(15)\n",
    "display(invalid_dob_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501f3ffe",
   "metadata": {},
   "source": [
    "The sample of invalid DOB rows shows that `applicant_info.date_of_birth` is stored in mixed string formats: `DD/MM/YYYY`, `YYYY/MM/DD`, or `MM/DD/YYYY`\n",
    "\n",
    "Because the column is not standardized to one format, `pd.to_datetime(..., errors=\"coerce\")` fails to parse a significant share of records, which are then coerced to `NaT`. In remediation, we will standardize DOBs to a single canonical format (e.g., ISO `YYYY-MM-DD`) by parsing with explicit rules and treating truly unparseable values as missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "id": "7c24eaf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DOB missing</th>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOB ISO-like (YYYY-MM-DD or YYYY/MM/DD)</th>\n",
       "      <td>396</td>\n",
       "      <td>78.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOB slash (DD/MM/YYYY or MM/DD/YYYY)</th>\n",
       "      <td>101</td>\n",
       "      <td>20.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOB ambiguous slash (both parts &lt;= 12)</th>\n",
       "      <td>39</td>\n",
       "      <td>7.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOB other format</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         count      %\n",
       "DOB missing                                  5   1.00\n",
       "DOB ISO-like (YYYY-MM-DD or YYYY/MM/DD)    396  78.88\n",
       "DOB slash (DD/MM/YYYY or MM/DD/YYYY)       101  20.12\n",
       "DOB ambiguous slash (both parts <= 12)      39   7.77\n",
       "DOB other format                             0   0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DOB format breakdown\n",
    "\n",
    "# Clean DOB strings\n",
    "dob = df_raw[\"applicant_info.date_of_birth\"].astype(\"string\").str.strip().replace({\"\": pd.NA})\n",
    "\n",
    "# Detect common DOB patterns\n",
    "iso = dob.str.match(r\"^\\d{4}[-/]\\d{2}[-/]\\d{2}$\", na=False)      # YYYY-MM-DD or YYYY/MM/DD\n",
    "slash = dob.str.match(r\"^\\d{2}/\\d{2}/\\d{4}$\", na=False)          # ??/??/YYYY\n",
    "\n",
    "# Flag ambiguous slash dates when both first numbers could be day or month\n",
    "p1 = pd.to_numeric(dob.str.slice(0, 2), errors=\"coerce\")\n",
    "p2 = pd.to_numeric(dob.str.slice(3, 5), errors=\"coerce\")\n",
    "ambig = slash & (p1 <= 12) & (p2 <= 12)\n",
    "\n",
    "# Build a summary table\n",
    "dob_summary = pd.DataFrame({\n",
    "    \"count\": [\n",
    "        dob.isna().sum(),\n",
    "        iso.sum(),\n",
    "        slash.sum(),\n",
    "        ambig.sum(),\n",
    "        (dob.notna() & ~(iso | slash)).sum()\n",
    "    ]\n",
    "}, index=[\n",
    "    \"DOB missing\",\n",
    "    \"DOB ISO-like (YYYY-MM-DD or YYYY/MM/DD)\",\n",
    "    \"DOB slash (DD/MM/YYYY or MM/DD/YYYY)\",\n",
    "    \"DOB ambiguous slash (both parts <= 12)\",\n",
    "    \"DOB other format\"\n",
    "])\n",
    "dob_summary[\"%\"] = (dob_summary[\"count\"] / len(dob) * 100).round(2)\n",
    "display(dob_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1680bc64",
   "metadata": {},
   "source": [
    "As shown most `applicant_info.date_of_birth` values are in an ISO-style format (`YYYY-MM-DD` or `YYYY/MM/DD`), which is straightforward to parse consistently.  \n",
    "\n",
    "A smaller share appears in a slash format (`??/??/YYYY`). This format can represent either `DD/MM/YYYY` or `MM/DD/YYYY`, and some values are ambiguous when both the day and month are ≤ 12.\n",
    "\n",
    "In the remediation, since the dataset doesn't specify the locale/date convention, we assume the ambiguous DOB values follow `DD/MM/YYYY`, once is the most common in the EU. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e48f367",
   "metadata": {},
   "source": [
    "### 2F. Invalid/impossible values \n",
    "\n",
    "**Dimension:** Validity\n",
    "\n",
    "#### 2F.1 Numeric fields\n",
    "\n",
    "In this step we validate key numeric fields by checking for values that are outside plausible ranges, such as negative balances/months, or ratios outside (0,1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "id": "3c6e87cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>pct_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>annual_income &lt; 0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_history_months &lt; 0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>debt_to_income &lt; 0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>debt_to_income &gt; 1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>savings_balance &lt; 0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interest_rate &lt; 0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interest_rate &gt; 1</th>\n",
       "      <td>292</td>\n",
       "      <td>58.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>approved_amount &lt; 0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           count  pct_%\n",
       "annual_income < 0              0   0.00\n",
       "credit_history_months < 0      2   0.40\n",
       "debt_to_income < 0             0   0.00\n",
       "debt_to_income > 1             1   0.20\n",
       "savings_balance < 0            1   0.20\n",
       "interest_rate < 0              0   0.00\n",
       "interest_rate > 1            292  58.17\n",
       "approved_amount < 0            0   0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert numeric-like columns to numbers (strings become numeric; bad values become NaN)\n",
    "income = pd.to_numeric(df_raw[\"financials.annual_income\"], errors=\"coerce\")\n",
    "chm    = pd.to_numeric(df_raw[\"financials.credit_history_months\"], errors=\"coerce\")\n",
    "dti    = pd.to_numeric(df_raw[\"financials.debt_to_income\"], errors=\"coerce\")\n",
    "sav    = pd.to_numeric(df_raw[\"financials.savings_balance\"], errors=\"coerce\")\n",
    "rate   = pd.to_numeric(df_raw[\"decision.interest_rate\"], errors=\"coerce\")\n",
    "amt    = pd.to_numeric(df_raw[\"decision.approved_amount\"], errors=\"coerce\")\n",
    "\n",
    "# Count values that violate basic business/validity rules\n",
    "invalid = {\n",
    "    \"annual_income < 0\": (income < 0).sum(),\n",
    "    \"credit_history_months < 0\": (chm < 0).sum(),\n",
    "    \"debt_to_income < 0\": (dti < 0).sum(),\n",
    "    \"debt_to_income > 1\": (dti > 1).sum(),\n",
    "    \"savings_balance < 0\": (sav < 0).sum(),\n",
    "    \"interest_rate < 0\": (rate < 0).sum(),\n",
    "    \"interest_rate > 1\": (rate > 1).sum(),  # if rate is stored as fraction; if it's % (e.g. 3.7), we'll adjust\n",
    "    \"approved_amount < 0\": (amt < 0).sum(),\n",
    "}\n",
    "\n",
    "# Build a reporting table with counts + percentages (of all rows)\n",
    "invalid_table = pd.DataFrame({\n",
    "    \"count\": pd.Series(invalid),\n",
    "    \"pct_%\": (pd.Series(invalid) / n * 100).round(2)\n",
    "})\n",
    "\n",
    "display(invalid_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ed0072",
   "metadata": {},
   "source": [
    "According to the table, most numeric fields respect basic validity rules, but we do observe a few issues: `financials.credit_history_months` has two negative values, which is impossible, `financials.debt_to_income` has one value above 1 (outside the expected [0,1] ratio), and `financials.savings_balance` includes a negative value.\n",
    "\n",
    "Additionally, `decision.interest_rate` appears “invalid” under a fraction-based rule (`> 1`). We will then check if the values represent percentages points instead of a [0,1] ratio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "id": "dcaca274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interest_rate outside [0, 100] percent: 0 (0.00%)\n",
      "interest_rate min/max (excluding NaN): 2.5 6.5\n"
     ]
    }
   ],
   "source": [
    "rate = pd.to_numeric(df_raw[\"decision.interest_rate\"], errors=\"coerce\")\n",
    "\n",
    "# Count rates outside a realistic percent range\n",
    "invalid_rate_pct = ((rate < 0) | (rate > 100)).sum()\n",
    "print(\"interest_rate outside [0, 100] percent:\", invalid_rate_pct, f\"({invalid_rate_pct/len(df_raw)*100:.2f}%)\")\n",
    "\n",
    "# Show min/max to justify treating this as percent points (not fractions)\n",
    "print(\"interest_rate min/max (excluding NaN):\", rate.min(), rate.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a6bc7c",
   "metadata": {},
   "source": [
    "The observed range (minimum 2.5 and maximum 6.5) indicates it is stored in percentage points, meaning 3.7 is 3.7%, so `> 1` is not treated as invalid. We validate interest rates using a percent range (0–100) instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572b6f59",
   "metadata": {},
   "source": [
    "#### 2F.2 Identifier-like fields\n",
    "##### SSN, ZIP, and Ip address"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150bccec",
   "metadata": {},
   "source": [
    "We validate identifier-like fields against basic format rules: \n",
    "- SSN should match `###-##-####`\n",
    "- ZIP code should be exactly 5 digits\n",
    "- IP address should be a valid IPv4 address (`###.###.###.###`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "id": "e8a21f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid SSN format: 0 (0.00%)\n",
      "Invalid ZIP format: 1 (0.20%)\n",
      "Invalid IP address: 0 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "# Read the three fields as strings\n",
    "ssn  = df_raw[\"applicant_info.ssn\"].astype(\"string\").str.strip()\n",
    "zipc = df_raw[\"applicant_info.zip_code\"].astype(\"string\").str.strip()\n",
    "ip   = df_raw[\"applicant_info.ip_address\"].astype(\"string\").str.strip()\n",
    "\n",
    "# SSN pattern ###-##-####\n",
    "ssn_invalid = ssn.dropna().str.match(r\"^\\d{3}-\\d{2}-\\d{4}$\") == False\n",
    "print(\"Invalid SSN format:\", ssn_invalid.sum(), f\"({ssn_invalid.sum()/len(df_raw)*100:.2f}%)\")\n",
    "\n",
    "# ZIP 5 digits (string)\n",
    "zip_invalid = zipc.dropna().str.match(r\"^\\d{5}$\") == False\n",
    "print(\"Invalid ZIP format:\", zip_invalid.sum(), f\"({zip_invalid.sum()/len(df_raw)*100:.2f}%)\")\n",
    "\n",
    "# IP valid IPv4\n",
    "def is_valid_ip(x):\n",
    "    if pd.isna(x):\n",
    "        return True\n",
    "    try:\n",
    "        ipaddress.ip_address(str(x))\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "ip_invalid = ip.dropna().map(lambda x: not is_valid_ip(x))\n",
    "print(\"Invalid IP address:\", ip_invalid.sum(), f\"({ip_invalid.sum()/len(df_raw)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "id": "269fc6df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>applicant_info.zip_code</th>\n",
       "      <th>applicant_info.ssn</th>\n",
       "      <th>applicant_info.full_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>app_075</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>Margaret Williams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        _id applicant_info.zip_code applicant_info.ssn  \\\n",
       "26  app_075                                        NaN   \n",
       "\n",
       "   applicant_info.full_name  \n",
       "26        Margaret Williams  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show rows where ZIP is present but not 5 digits\n",
    "zipc = df_raw[\"applicant_info.zip_code\"].astype(\"string\")\n",
    "bad_zip_mask = zipc.notna() & (zipc.str.match(r\"^\\d{5}$\") == False)\n",
    "\n",
    "display(df_raw.loc[bad_zip_mask, [\"_id\", \"applicant_info.zip_code\", \"applicant_info.ssn\", \"applicant_info.full_name\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ec24a8",
   "metadata": {},
   "source": [
    "SSN and IP formats are fully valid in the dataset.  \n",
    "\n",
    "We found 1 invalid ZIP (0.20%), which is a blank string. We will convert it to missing in the remediation.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44265e66",
   "metadata": {},
   "source": [
    "##### Email \n",
    "\n",
    "Now we check `applicant_info.email` to see if the value contains an `@`, and the domain part contains at least one dot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "id": "ccb67090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emails missing: 7 (1.39%)\n",
      "Missing/invalid domain (no @): 1 (0.20%)\n",
      "Domain bad format (no dot): 2 (0.40%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>applicant_info.email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>app_299</td>\n",
       "      <td>test.user.outlook.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>app_068</td>\n",
       "      <td>john.doe@invalid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>app_146</td>\n",
       "      <td>sarah.smith@</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         _id   applicant_info.email\n",
       "181  app_299  test.user.outlook.com\n",
       "276  app_068       john.doe@invalid\n",
       "369  app_146           sarah.smith@"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "applicant_info.email\n",
       "gmail.com         72\n",
       "yahoo.com         70\n",
       "mail.com          68\n",
       "outlook.com       68\n",
       "protonmail.com    61\n",
       "hotmail.com       56\n",
       "aol.com           50\n",
       "icloud.com        47\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Clean email column: cast to string, trim spaces, turn \"\" into missing\n",
    "email = df_raw[\"applicant_info.email\"].astype(\"string\").str.strip()\n",
    "email = email.replace({\"\": pd.NA})\n",
    "\n",
    "# Basic structure check: must contain \"@\"\n",
    "has_at = email.notna() & email.str.contains(\"@\", na=False)\n",
    "\n",
    "# Extract domain (everything after \"@\") for rows that have \"@\"\n",
    "domain = email.where(has_at).str.split(\"@\", n=1).str[1].str.lower().str.strip()\n",
    "\n",
    "# Define invalid cases we want to count\n",
    "missing_at  = email.notna() & ~has_at                              # no \"@\"\n",
    "bad_domain  = has_at & (~domain.str.contains(r\"\\.\", na=False))     # domain has no dot\n",
    "empty_email = email.isna()\n",
    "\n",
    "print(\"Emails missing:\", int(empty_email.sum()), f\"({empty_email.mean()*100:.2f}%)\")\n",
    "print(\"Missing/invalid domain (no @):\", int(missing_at.sum()), f\"({missing_at.mean()*100:.2f}%)\")\n",
    "print(\"Domain bad format (no dot):\", int(bad_domain.sum()), f\"({bad_domain.mean()*100:.2f}%)\")\n",
    "\n",
    "# Show examples of invalid cases\n",
    "display(df_raw.loc[missing_at | bad_domain, [\"_id\", \"applicant_info.email\"]].head(15))\n",
    "\n",
    "# Domain counts (valid only)\n",
    "valid_domain = has_at & ~bad_domain\n",
    "display(domain[valid_domain].value_counts().head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99f8c4c",
   "metadata": {},
   "source": [
    "Most emails follow a valid-looking structure, but a small number fail basic formatting checks: \n",
    "- 7 emails are missing (1.39%)\n",
    "- 1 value is missing `@` (0.20%)\n",
    "- 2 values have a domain with no dot (0.40%).\n",
    "\n",
    "To remediate this, we convert blank strings to missing (`NA`) and treat emails that miss `@` or have invalid domain as missing rather than guessing or correcting them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cc69d5",
   "metadata": {},
   "source": [
    "### 2G. Cross-field consistency checks \n",
    "\n",
    "**Dimension:** Accuracy\n",
    "\n",
    "We verify that related decision fields are consistent:\n",
    "- Approved loans should have `approved_amount` and `interest_rate`, and should not have `rejection_reason`.\n",
    "- Denied loans should have `rejection_reason`, and should not have approval terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "id": "778b81d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approved but missing approved_amount or interest_rate: 0\n",
      "Approved but has rejection_reason: 0\n",
      "Denied but missing rejection_reason: 0\n",
      "Denied but has approved_amount or interest_rate: 0\n"
     ]
    }
   ],
   "source": [
    "approved = df_raw[\"decision.loan_approved\"] == True\n",
    "denied   = df_raw[\"decision.loan_approved\"] == False\n",
    "\n",
    "# Approved but missing terms\n",
    "approved_missing_terms = approved & (\n",
    "    df_raw[\"decision.approved_amount\"].isna() | df_raw[\"decision.interest_rate\"].isna()\n",
    ")\n",
    "\n",
    "# Approved but has rejection reason\n",
    "approved_has_rejection = approved & df_raw[\"decision.rejection_reason\"].notna()\n",
    "\n",
    "# Denied but missing rejection reason\n",
    "denied_missing_rejection = denied & df_raw[\"decision.rejection_reason\"].isna()\n",
    "\n",
    "# Denied but has terms\n",
    "denied_has_terms = denied & (\n",
    "    df_raw[\"decision.approved_amount\"].notna() | df_raw[\"decision.interest_rate\"].notna()\n",
    ")\n",
    "\n",
    "print(\"Approved but missing approved_amount or interest_rate:\", int(approved_missing_terms.sum()))\n",
    "print(\"Approved but has rejection_reason:\", int(approved_has_rejection.sum()))\n",
    "print(\"Denied but missing rejection_reason:\", int(denied_missing_rejection.sum()))\n",
    "print(\"Denied but has approved_amount or interest_rate:\", int(denied_has_terms.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79407a85",
   "metadata": {},
   "source": [
    "No inconsistencies were found."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36de3dc8",
   "metadata": {},
   "source": [
    "### 2H. Key findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d348faf8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9b6b85f",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Remediation: Cleaning pipeline\n",
    "---\n",
    "\n",
    "In this section we apply the cleaning steps needed to address the issues identified in the data quality checks. The goal is to produce a consistent, analysis-ready dataset while preserving as much information as possible. \n",
    "\n",
    "In general, we apply field-level fixes (standardizing formats and setting invalid values to `NA`) and only remove records when necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f128292d",
   "metadata": {},
   "source": [
    "### 3A. Remove duplicate application IDs\n",
    "\n",
    "To work with one row per application, we first resolve duplicated `_id` values. When the same `_id` appears more than once, we keep the version of the record that is more complete (the one with more filled-in fields) and drop the extra duplicate rows. This gives us a single, best representative record for each application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "id": "71560c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate _id after remediation: 0\n",
      "Rows after _id dedupe: 500\n"
     ]
    }
   ],
   "source": [
    "# Start remediation from the raw dataframe\n",
    "df_clean = df_raw.copy()\n",
    "\n",
    "# Count non-missing values across all columns\n",
    "df_clean[\"_non_missing\"] = df_clean.notna().sum(axis=1)\n",
    "\n",
    "# Sort so the most complete row per _id comes first\n",
    "df_clean = df_clean.sort_values([\"_id\", \"_non_missing\"], ascending=[True, False])\n",
    "\n",
    "# Keep one row per _id\n",
    "df_clean = df_clean.drop_duplicates(subset=[\"_id\"], keep=\"first\").drop(columns=[\"_non_missing\"])\n",
    "\n",
    "# Quick check\n",
    "print(\"Duplicate _id after remediation:\", int(df_clean[\"_id\"].duplicated().sum()))\n",
    "print(\"Rows after _id dedupe:\", len(df_clean))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fddb2b9",
   "metadata": {},
   "source": [
    "### 3B. Flag duplicate SSNs\n",
    "\n",
    "We don't automatically drop duplicate SSNs. Since the records have different applicant names, we treat these as identifier conflicts and flag them for review. In the cleaned dataset, we keep both rows but mark ssn_is_duplicate = True and set the SSN to missing so it isn't used as a reliable identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "id": "8691be94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with duplicate SSN: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>applicant_info.ssn</th>\n",
       "      <th>applicant_info.full_name</th>\n",
       "      <th>ssn_is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>app_016</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Gary Wilson</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>app_088</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Susan Martinez</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>app_101</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Sandra Smith</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>app_234</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Samuel Hill</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         _id applicant_info.ssn applicant_info.full_name  ssn_is_duplicate\n",
       "122  app_016               <NA>              Gary Wilson              True\n",
       "92   app_088               <NA>           Susan Martinez              True\n",
       "16   app_101               <NA>             Sandra Smith              True\n",
       "499  app_234               <NA>              Samuel Hill              True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Flag SSNs that appear in more than one row, ignoring missing SSNs\n",
    "ssn = df_clean[\"applicant_info.ssn\"]\n",
    "\n",
    "df_clean[\"ssn_is_duplicate\"] = ssn.notna() & ssn.duplicated(keep=False)\n",
    "\n",
    "# Set SSN to missing for duplicated SSNs \n",
    "df_clean.loc[df_clean[\"ssn_is_duplicate\"], \"applicant_info.ssn\"] = pd.NA\n",
    "\n",
    "# Quick check and show examples\n",
    "print(\"Rows with duplicate SSN:\", int(df_clean[\"ssn_is_duplicate\"].sum()))\n",
    "\n",
    "display(\n",
    "    df_clean.loc[\n",
    "        df_clean[\"ssn_is_duplicate\"],\n",
    "        [\"_id\", \"applicant_info.ssn\", \"applicant_info.full_name\", \"ssn_is_duplicate\"]\n",
    "    ].head(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15563550",
   "metadata": {},
   "source": [
    "### 3C. Convert blank strings to missing values\n",
    "\n",
    "Some text fields contain blank strings (`\"\"` or `\"   \"`) instead of true missing values. To handle missingness consistently across the dataset, we trim whitespace and convert blank strings to `NA` for all text-like columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "id": "6d8d2ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total blank strings remaining: 0\n"
     ]
    }
   ],
   "source": [
    "# Select text-like columns\n",
    "text_cols = df_clean.select_dtypes(include=[\"object\", \"string\"]).columns\n",
    "\n",
    "# Trim whitespace and convert \"\" to NA\n",
    "df_clean[text_cols] = df_clean[text_cols].astype(\"string\").apply(lambda s: s.str.strip())\n",
    "df_clean[text_cols] = df_clean[text_cols].replace({\"\": pd.NA})\n",
    "\n",
    "# Quick check: number of blank strings remaining\n",
    "blank_remaining = df_clean[text_cols].apply(lambda s: s.astype(\"string\").str.strip().eq(\"\").sum()).sum()\n",
    "print(\"Total blank strings remaining:\", int(blank_remaining))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aa2222",
   "metadata": {},
   "source": [
    "### 3D. Unify yearly income\n",
    "\n",
    "The dataset stores the same concept (yearly income) in two different columns: `financials.annual_income` and `financials.annual_salary`. \n",
    "We first convert both columns to numeric (solving the issue with string entries in the variable), then fill missing `annual_income` with `annual_salary` and drop `annual_salary` to keep one canonical income field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "id": "ce6c9f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing annual_income: 0\n",
      "annual_salary column exists? False\n"
     ]
    }
   ],
   "source": [
    "# Convert both columns to numeric\n",
    "df_clean[\"financials.annual_income\"] = pd.to_numeric(df_clean[\"financials.annual_income\"], errors=\"coerce\")\n",
    "df_clean[\"financials.annual_salary\"] = pd.to_numeric(df_clean[\"financials.annual_salary\"], errors=\"coerce\")\n",
    "\n",
    "# Fill missing annual_income with annual_salary\n",
    "df_clean[\"financials.annual_income\"] = df_clean[\"financials.annual_income\"].fillna(df_clean[\"financials.annual_salary\"])\n",
    "\n",
    "# Drop annual_salary to keep one canonical income field\n",
    "df_clean = df_clean.drop(columns=[\"financials.annual_salary\"])\n",
    "\n",
    "# Quick check: remaining missing annual_income + confirm salary is gone\n",
    "print(\"Missing annual_income:\", int(df_clean[\"financials.annual_income\"].isna().sum()))\n",
    "print(\"annual_salary column exists?\", \"financials.annual_salary\" in df_clean.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdd89dd",
   "metadata": {},
   "source": [
    "### 3E. Standardize gender coding\n",
    "\n",
    "To keep categorical analysis consistent, we standardize `applicant_info.gender` so shorthand codes (`M`/`F`) are mapped to the full labels (`Male`/`Female`). Any remaining blanks are already handled as `NA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "id": "f5b7b2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "applicant_info.gender\n",
       "Female    251\n",
       "Male      247\n",
       "<NA>        2\n",
       "Name: count, dtype: Int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Standardize shorthand to full labels\n",
    "df_clean[\"applicant_info.gender\"] = (\n",
    "    df_clean[\"applicant_info.gender\"]\n",
    "    .astype(\"string\")\n",
    "    .replace({\"M\": \"Male\", \"F\": \"Female\"})\n",
    ")\n",
    "\n",
    "# Quick check (after): value counts\n",
    "display(df_clean[\"applicant_info.gender\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54256228",
   "metadata": {},
   "source": [
    "### 3F. Standardize date of birth format\n",
    "\n",
    "`applicant_info.date_of_birth` appears in multiple formats. To make the field consistent, we parse the values and store them in a single standard format: `DD-MM-YYYY`. For slash-formatted dates where day/month order isn't explicit, we assume the `DD/MM/YYYY` format, since it's the most common convention in Europe and the dataset doesn't provide any data indicating a location or date standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "id": "fb06aa98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining unparseable DOB: 0\n",
      "Standardized DOB (non-missing): 496\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>applicant_info.date_of_birth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>app_001</td>\n",
       "      <td>27-05-1986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>app_002</td>\n",
       "      <td>01-08-1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>app_003</td>\n",
       "      <td>24-08-1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>app_004</td>\n",
       "      <td>28-02-1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>app_005</td>\n",
       "      <td>19-06-1960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>app_006</td>\n",
       "      <td>12-07-1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>app_007</td>\n",
       "      <td>13-06-1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>app_008</td>\n",
       "      <td>12-07-1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>app_009</td>\n",
       "      <td>20-11-1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>app_010</td>\n",
       "      <td>07-09-1996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         _id applicant_info.date_of_birth\n",
       "383  app_001                   27-05-1986\n",
       "339  app_002                   01-08-1999\n",
       "284  app_003                   24-08-1982\n",
       "255  app_004                   28-02-1995\n",
       "136  app_005                   19-06-1960\n",
       "328  app_006                   12-07-1987\n",
       "12   app_007                   13-06-1989\n",
       "81   app_008                   12-07-1993\n",
       "390  app_009                   20-11-1989\n",
       "47   app_010                   07-09-1996"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Clean raw DOB strings\n",
    "dob_raw = (\n",
    "    df_clean[\"applicant_info.date_of_birth\"]\n",
    "    .astype(\"string\")\n",
    "    .str.strip()\n",
    "    .replace({\"\": pd.NA})\n",
    ")\n",
    "\n",
    "# Start empty datetime series\n",
    "dob_dt = pd.Series(pd.NaT, index=df_clean.index)\n",
    "\n",
    "# YYYY-MM-DD\n",
    "m = dob_raw.notna() & dob_raw.str.match(r\"^\\d{4}-\\d{2}-\\d{2}$\", na=False)\n",
    "dob_dt.loc[m] = pd.to_datetime(dob_raw.loc[m], errors=\"coerce\", format=\"%Y-%m-%d\")\n",
    "\n",
    "# YYYY/MM/DD\n",
    "m = dob_raw.notna() & dob_raw.str.match(r\"^\\d{4}/\\d{2}/\\d{2}$\", na=False)\n",
    "dob_dt.loc[m] = pd.to_datetime(dob_raw.loc[m], errors=\"coerce\", format=\"%Y/%m/%d\")\n",
    "\n",
    "# Slash format: try DD/MM/YYYY first (assumption)\n",
    "m_slash = dob_raw.notna() & dob_raw.str.match(r\"^\\d{2}/\\d{2}/\\d{4}$\", na=False)\n",
    "dob_dt.loc[m_slash] = pd.to_datetime(dob_raw.loc[m_slash], errors=\"coerce\", format=\"%d/%m/%Y\")\n",
    "\n",
    "# Fallback: MM/DD/YYYY only for the ones DD/MM couldn't parse\n",
    "m_mdy = m_slash & dob_dt.isna()\n",
    "dob_dt.loc[m_mdy] = pd.to_datetime(dob_raw.loc[m_mdy], errors=\"coerce\", format=\"%m/%d/%Y\")\n",
    "\n",
    "# Store standardized string format (DD-MM-YYYY)\n",
    "df_clean[\"applicant_info.date_of_birth\"] = dob_dt.dt.strftime(\"%d-%m-%Y\").astype(\"string\")\n",
    "\n",
    "# Quick check\n",
    "still_bad = dob_raw.notna() & dob_dt.isna()\n",
    "print(\"Remaining unparseable DOB:\", int(still_bad.sum()))\n",
    "\n",
    "# Show examples of standardized (valid) DOBs\n",
    "good_dob = df_clean[\"applicant_info.date_of_birth\"].notna()\n",
    "\n",
    "print(\"Standardized DOB (non-missing):\", int(good_dob.sum()))\n",
    "display(df_clean.loc[good_dob, [\"_id\", \"applicant_info.date_of_birth\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31cfeeb",
   "metadata": {},
   "source": [
    "### 3G. Fixing invalid / impossible values\n",
    "\n",
    "#### 3G.1 Impossible numeric values\n",
    "\n",
    "We correct the impossible numeric values (negative months, negative savings balances, and a debt-to-income ratio above 1). Instead of dropping whole rows, we set those specific values to missing (NA) so the record can still be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "id": "e9966506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "credit_history_months < 0: 0\n",
      "debt_to_income > 1: 0\n",
      "savings_balance < 0: 0\n"
     ]
    }
   ],
   "source": [
    "# Coerce to numeric\n",
    "chm = pd.to_numeric(df_clean[\"financials.credit_history_months\"], errors=\"coerce\")\n",
    "dti = pd.to_numeric(df_clean[\"financials.debt_to_income\"], errors=\"coerce\")\n",
    "sav = pd.to_numeric(df_clean[\"financials.savings_balance\"], errors=\"coerce\")\n",
    "\n",
    "# Masks for impossible values\n",
    "bad_chm = chm < 0\n",
    "bad_dti = dti > 1\n",
    "bad_sav = sav < 0\n",
    "\n",
    "# Apply fixes (set to missing)\n",
    "df_clean.loc[bad_chm, \"financials.credit_history_months\"] = pd.NA\n",
    "df_clean.loc[bad_dti, \"financials.debt_to_income\"] = pd.NA\n",
    "df_clean.loc[bad_sav, \"financials.savings_balance\"] = pd.NA\n",
    "\n",
    "# Quick checks (should be 0 after remediation)\n",
    "print(\"credit_history_months < 0:\", int(pd.to_numeric(df_clean[\"financials.credit_history_months\"], errors=\"coerce\").lt(0).sum()))\n",
    "print(\"debt_to_income > 1:\", int(pd.to_numeric(df_clean[\"financials.debt_to_income\"], errors=\"coerce\").gt(1).sum()))\n",
    "print(\"savings_balance < 0:\", int(pd.to_numeric(df_clean[\"financials.savings_balance\"], errors=\"coerce\").lt(0).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fd1156",
   "metadata": {},
   "source": [
    "#### 3G.2 Invalid emails\n",
    "\n",
    "To keep contact fields consistent, we treat emails as valid only when they contain an `@` and the domain contains a dot. The remaining are set to missing (`NA`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "id": "a53be4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid email (missing @): 1\n",
      "Invalid email (bad domain): 2\n",
      "Remaining invalid emails: 0\n"
     ]
    }
   ],
   "source": [
    "# Clean emails\n",
    "email = df_clean[\"applicant_info.email\"].astype(\"string\").str.strip()\n",
    "has_at = email.notna() & email.str.contains(\"@\", na=False)\n",
    "\n",
    "# Domain = part after \"@\"\n",
    "domain = email.where(has_at).str.split(\"@\", n=1).str[1].str.lower().str.strip()\n",
    "\n",
    "# Invalid cases\n",
    "missing_at = email.notna() & ~has_at\n",
    "bad_domain = has_at & (~domain.str.contains(r\"\\.\", na=False))\n",
    "\n",
    "# Quick check (before)\n",
    "print(\"Invalid email (missing @):\", int(missing_at.sum()))\n",
    "print(\"Invalid email (bad domain):\", int(bad_domain.sum()))\n",
    "\n",
    "# Set invalid emails to missing\n",
    "df_clean.loc[missing_at | bad_domain, \"applicant_info.email\"] = pd.NA\n",
    "\n",
    "# Quick check (after)\n",
    "email_after = df_clean[\"applicant_info.email\"].astype(\"string\")\n",
    "print(\"Remaining invalid emails:\", int((email_after.notna() & ~email_after.str.contains(\"@\", na=False)).sum()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
